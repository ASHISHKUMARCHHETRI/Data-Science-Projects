{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading clik_list \n",
    "url_data=pd.read_excel(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\cik_list.xlsx\")\n",
    "\n",
    "#loading master data\n",
    "master_data=pd.read_csv(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\LoughranMcDonald_MasterDictionary_2018.csv\")\n",
    "\n",
    "#loading uncertainity and data \n",
    "uncertainity=pd.read_excel(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\uncertainty_dictionary.xlsx\")\n",
    "constraining_dictionary=pd.read_excel(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\constraining_dictionary.xlsx\")\n",
    "\n",
    "# making list of all url\n",
    "url=[]\n",
    "for i in url_data[\"SECFNAME\"]:\n",
    "    url.append(\"https://www.sec.gov/Archives/\"+i)\n",
    "    \n",
    "# getting words from dictionary \n",
    "Dict_words=[i for i in master_data[\"Word\"]]\n",
    "Dict_words=str(Dict_words)\n",
    "Dict_words=Dict_words.lower()\n",
    "\n",
    "# getting positive words\n",
    "df1=master_data[[\"Word\",\"Positive\",\"Negative\"]]\n",
    "positive_words=[]\n",
    "for i,j in zip(df1[\"Word\"],df1[\"Positive\"]):\n",
    "    if j!=0:\n",
    "        positive_words.append(i)\n",
    "positive_words=str(positive_words)\n",
    "positive_words=positive_words.lower()\n",
    "\n",
    "# getting negative words\n",
    "negative_words=[]\n",
    "for i,j in zip(df1[\"Word\"],df1[\"Negative\"]):\n",
    "    if j!=0:\n",
    "        negative_words.append(i)\n",
    "negative_words=str(negative_words)\n",
    "negative_words=negative_words.lower()\n",
    "\n",
    "# getting text from url\n",
    "def scrap(url):\n",
    "    u=url\n",
    "    webpage=requests.get(u)\n",
    "    soup=BeautifulSoup(webpage.text,\"html.parser\")\n",
    "    return soup\n",
    "txt1=scrap(url[0])\n",
    "txt1=str(txt1)\n",
    "txt2=txt1.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score1=[]\n",
    "negative_score1=[]\n",
    "polarity_score1=[]\n",
    "average_sentence_length1=[]\n",
    "percentage_of_complex_words1=[]\n",
    "fog_index1=[]\n",
    "complex_word_count1=[]\n",
    "word_count1=[]\n",
    "uncertainty_score1=[]\n",
    "constraining_score1=[]\n",
    "positive_word_proportion1=[]\n",
    "negative_word_proportion1=[]\n",
    "uncertainty_word_proportion1=[]\n",
    "constraining_word_proportion1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0-20):\n",
    "\n",
    "        txt1=scrap(url[i])\n",
    "        txt1=str(txt1)\n",
    "        txt2=txt1.lower()\n",
    "        #cleaning the text\n",
    "        c1=re.sub(\"\\d\",\"\",txt2)\n",
    "        c1=re.sub(\"\\W\",\" \",c1)\n",
    "        c1=res = re.sub(' +', ' ', c1)\n",
    "        res=re.sub(r\"[^\\w\\s]\",\"\",c1)\n",
    "        res=re.sub(\"www\",\"\",res)\n",
    "        res=re.sub(\"______\",\"\",res)\n",
    "\n",
    "        # tokenization\n",
    "        tokens=word_tokenize(res)\n",
    "        w=[]\n",
    "\n",
    "        #Personal Pronouns\n",
    "        P=['I', 'we',' my',' ours','us']\n",
    "        Personal_Pronouns=[]\n",
    "        for i in P:\n",
    "            if i in txt1:\n",
    "                Personal_Pronouns.append(1)\n",
    "\n",
    "        #removing stopwords\n",
    "        for word in tokens:\n",
    "                if not word in stopwords.words(\"english\"):\n",
    "                    w.append(word)\n",
    "\n",
    "        # removing words greater than length 15 and less than 2\n",
    "        for i in w:\n",
    "            if len(i)>15 or len(i)<2:\n",
    "                w.remove(i)\n",
    "\n",
    "        # taking only those words which are in dictionary and our cleaned word\n",
    "        word=[]\n",
    "        for i in w:\n",
    "            if i in Dict_words:\n",
    "                word.append(i)\n",
    "\n",
    "\n",
    "        # lemmatizing based on pos_tag\n",
    "        pos_tag=nltk.pos_tag(word)\n",
    "        lemma=WordNetLemmatizer()\n",
    "        for i in range(len(pos_tag)):\n",
    "            if pos_tag[i][1]=='RB':\n",
    "                    lemma.lemmatize(word[i],pos=\"a\")\n",
    "            elif pos_tag[i][1]=='VBG':\n",
    "                lemma.lemmatize(word[i],pos=\"v\")\n",
    "            elif pos_tag[i][1]==\"NN\":\n",
    "                lemma.lemmatize(word[i],pos=\"n\")\n",
    "            else:          \n",
    "                lemma.lemmatize(word[i])\n",
    "\n",
    "\n",
    "        # calculating Positive score\n",
    "        positive_score=[]\n",
    "        for i in word:\n",
    "            if i in positive_words:\n",
    "                positive_score.append(1)\n",
    "        positive_score=sum(positive_score)\n",
    "\n",
    "        # Calculating Negative score\n",
    "        negative_score=[]\n",
    "        for i in word:\n",
    "            if i in negative_words:\n",
    "                negative_score.append(1)\n",
    "        negative_score=sum(negative_score)\n",
    "\n",
    "        #Calculating Polarity score + Word count\n",
    "        Polarity_Score = (positive_score-negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "        Polarity_Score \n",
    "        Word_Count=len(word)\n",
    "\n",
    "        # Syllable count per word + complex word count\n",
    "        vowels=[\"a\",\"e\",\"i\",\"o\",\"u\"]\n",
    "        no=[\"es\",\"ed\"]\n",
    "        Complex_word_count=[]\n",
    "        for i in word:\n",
    "            Syllable_Count_Per_Word=[]\n",
    "            for j in i:\n",
    "                if j in vowels and j not in no:\n",
    "                    Syllable_Count_Per_Word.append(1)\n",
    "            if sum(Syllable_Count_Per_Word)>2:\n",
    "                Complex_word_count.append(1)\n",
    "        Complex_word_count=sum(Complex_word_count)\n",
    "\n",
    "\n",
    "        # Calculationg Average Sentence length\n",
    "        sent=sent_tokenize(txt2)\n",
    "        avg_sentence_length=len(word)/len(sent)\n",
    "\n",
    "        #Percentage_of Complex words\n",
    "        Percentage_of_Complex_words = Complex_word_count/len(word) \n",
    "\n",
    "        #Fog_index\n",
    "        Fog_Index= 0.4*(avg_sentence_length + Percentage_of_Complex_words)\n",
    "\n",
    "        #9Average Word Length\n",
    "        Average_Word_Length=round(sum([len(i) for i in tokens])/len(tokens),2)\n",
    "        Average_Word_Length\n",
    "\n",
    "        # Calculating uncertaininty score \n",
    "        uncertainity_score=[]\n",
    "        for i in word:\n",
    "            if i in str(uncertainity[\"Word\"]).lower():\n",
    "                uncertainity_score.append(1)\n",
    "        uncertainity_score=sum(uncertainity_score)\n",
    "\n",
    "        # Calculating constraining score\n",
    "        constraining_score=[]\n",
    "        for i in word:\n",
    "            if i in str(constraining_dictionary[\"Word\"]).lower():\n",
    "                constraining_score.append(1)\n",
    "        constraining_score=sum(constraining_score)\n",
    "\n",
    "        #positive word proportion\n",
    "        positive_word_prportion=positive_score/len(word)\n",
    "\n",
    "        #negative word proportion\n",
    "        negative_word_proportion=negative_score/len(word)\n",
    "\n",
    "        #constraining word proportion\n",
    "        constraining_word_prportion=constraining_score/len(word)\n",
    "\n",
    "        #uncertainity word proportion\n",
    "        uncertainity_word_prportion=uncertainity_score/len(word)\n",
    "\n",
    "\n",
    "        #apending all the values inside the variables\n",
    "        positive_score1.append(positive_score), negative_score1.append(negative_score), polarity_score1.append(Polarity_Score),\n",
    "        average_sentence_length1.append(avg_sentence_length), percentage_of_complex_words1.append(Percentage_of_Complex_words),\n",
    "        fog_index1.append(Fog_Index), complex_word_count1.append(Complex_word_count), word_count1.append(Word_Count),\n",
    "        uncertainty_score1.append(uncertainity_score), constraining_score1.append(constraining_score),\n",
    "        positive_word_proportion1.append(positive_word_prportion), negative_word_proportion1.append(negative_word_proportion),\n",
    "        uncertainty_word_proportion1.append(uncertainity_word_prportion), constraining_word_proportion1.append(uncertainity_word_prportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12504.0</td>\n",
       "      <td>44303.0</td>\n",
       "      <td>-0.559773</td>\n",
       "      <td>326.216092</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>130.522720</td>\n",
       "      <td>12872.0</td>\n",
       "      <td>141904.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>0.088116</td>\n",
       "      <td>0.312204</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>-0.548023</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>0.366292</td>\n",
       "      <td>12.013184</td>\n",
       "      <td>163.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.307865</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.035955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49039.0</td>\n",
       "      <td>164412.0</td>\n",
       "      <td>-0.540513</td>\n",
       "      <td>328.364300</td>\n",
       "      <td>0.089943</td>\n",
       "      <td>131.381697</td>\n",
       "      <td>44508.0</td>\n",
       "      <td>494845.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.332249</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8005.0</td>\n",
       "      <td>28566.0</td>\n",
       "      <td>-0.562221</td>\n",
       "      <td>335.941176</td>\n",
       "      <td>0.086795</td>\n",
       "      <td>134.411189</td>\n",
       "      <td>7931.0</td>\n",
       "      <td>91376.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>0.087605</td>\n",
       "      <td>0.312620</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68018.0</td>\n",
       "      <td>153829.0</td>\n",
       "      <td>-0.386803</td>\n",
       "      <td>65.591516</td>\n",
       "      <td>0.076134</td>\n",
       "      <td>26.267060</td>\n",
       "      <td>19071.0</td>\n",
       "      <td>250494.0</td>\n",
       "      <td>82626.0</td>\n",
       "      <td>50541.0</td>\n",
       "      <td>0.271535</td>\n",
       "      <td>0.614103</td>\n",
       "      <td>0.329852</td>\n",
       "      <td>0.329852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33023.0</td>\n",
       "      <td>83658.0</td>\n",
       "      <td>-0.433961</td>\n",
       "      <td>126.529464</td>\n",
       "      <td>0.110914</td>\n",
       "      <td>50.656151</td>\n",
       "      <td>15718.0</td>\n",
       "      <td>141713.0</td>\n",
       "      <td>32543.0</td>\n",
       "      <td>23329.0</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.590334</td>\n",
       "      <td>0.229640</td>\n",
       "      <td>0.229640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>174.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>2.453771</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>1.191127</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.086267</td>\n",
       "      <td>0.287556</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>-0.497810</td>\n",
       "      <td>2.419589</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>1.170734</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.085957</td>\n",
       "      <td>0.256372</td>\n",
       "      <td>0.024488</td>\n",
       "      <td>0.024488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>998.0</td>\n",
       "      <td>4339.0</td>\n",
       "      <td>-0.626007</td>\n",
       "      <td>22.169211</td>\n",
       "      <td>0.552999</td>\n",
       "      <td>9.088884</td>\n",
       "      <td>9636.0</td>\n",
       "      <td>17425.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.249010</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.009756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>-0.694750</td>\n",
       "      <td>21.735043</td>\n",
       "      <td>0.571766</td>\n",
       "      <td>8.922723</td>\n",
       "      <td>2908.0</td>\n",
       "      <td>5086.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.049155</td>\n",
       "      <td>0.272906</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.009438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2           3         4           5        6  \\\n",
       "0  12504.0   44303.0 -0.559773  326.216092  0.090709  130.522720  12872.0   \n",
       "1     40.0     137.0 -0.548023   29.666667  0.366292   12.013184    163.0   \n",
       "2  49039.0  164412.0 -0.540513  328.364300  0.089943  131.381697  44508.0   \n",
       "3   8005.0   28566.0 -0.562221  335.941176  0.086795  134.411189   7931.0   \n",
       "4  68018.0  153829.0 -0.386803   65.591516  0.076134   26.267060  19071.0   \n",
       "5  33023.0   83658.0 -0.433961  126.529464  0.110914   50.656151  15718.0   \n",
       "6    174.0     580.0 -0.538462    2.453771  0.524046    1.191127   1057.0   \n",
       "7    172.0     513.0 -0.497810    2.419589  0.507246    1.170734   1015.0   \n",
       "8    998.0    4339.0 -0.626007   22.169211  0.552999    9.088884   9636.0   \n",
       "9    250.0    1388.0 -0.694750   21.735043  0.571766    8.922723   2908.0   \n",
       "\n",
       "          7        8        9        10        11        12        13  \n",
       "0  141904.0     57.0   1798.0  0.088116  0.312204  0.000402  0.000402  \n",
       "1     445.0     16.0     25.0  0.089888  0.307865  0.035955  0.035955  \n",
       "2  494845.0    275.0   7583.0  0.099100  0.332249  0.000556  0.000556  \n",
       "3   91376.0     53.0   1210.0  0.087605  0.312620  0.000580  0.000580  \n",
       "4  250494.0  82626.0  50541.0  0.271535  0.614103  0.329852  0.329852  \n",
       "5  141713.0  32543.0  23329.0  0.233027  0.590334  0.229640  0.229640  \n",
       "6    2017.0     39.0     46.0  0.086267  0.287556  0.019336  0.019336  \n",
       "7    2001.0     49.0     59.0  0.085957  0.256372  0.024488  0.024488  \n",
       "8   17425.0    170.0    298.0  0.057274  0.249010  0.009756  0.009756  \n",
       "9    5086.0     48.0     71.0  0.049155  0.272906  0.009438  0.009438  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables=[positive_score1,\n",
    "    negative_score1,\n",
    "    polarity_score1,\n",
    "    average_sentence_length1,\n",
    "    percentage_of_complex_words1,\n",
    "    fog_index1,\n",
    "    complex_word_count1,\n",
    "    word_count1,\n",
    "    uncertainty_score1,\n",
    "    constraining_score1,\n",
    "    positive_word_proportion1,\n",
    "    negative_word_proportion1,\n",
    "    uncertainty_word_proportion1,\n",
    "    constraining_word_proportion1]\n",
    "output=pd.DataFrame(variables)\n",
    "output=output.T\n",
    "c=output\n",
    "output.to_csv(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\output_files\\output(0-20).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=\"C:/Mba notes/novels/Intern Dataset/Text Analysis/output_files\"\n",
    "join=os.listdir(path)\n",
    "final_path=[]\n",
    "for i in join:\n",
    "    fp=os.path.join(path,i)\n",
    "    final_path.append(fp)\n",
    "dfs=[]\n",
    "for i in final_path:\n",
    "    f=pd.read_csv(i)\n",
    "    dfs.append(f)\n",
    "data=pd.concat(dfs,ignore_index=True)\n",
    "output=pd.read_csv(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\output.csv\")\n",
    "output_data_stucture=pd.read_excel(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\Structure.xlsx\")\n",
    "output_data_stucture=output_data_stucture.drop([\"CIK\",\"CONAME\",\"FYRMO\",\"FDATE\",\"FORM\",\"SECFNAME\",\"constraining_words_whole_report\"],1)\n",
    "output.columns=output_data_stucture.columns\n",
    "final_output=pd.concat([url_data,output],1)\n",
    "final_output[\"constraining_words_whole_report\"]=final_output[\"word_count\"]/final_output[\"constraining_score\"]\n",
    "final_output.to_csv(r\"C:\\Mba notes\\novels\\Intern Dataset\\Text Analysis\\final_output_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>...</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uncertainty_score</th>\n",
       "      <th>constraining_score</th>\n",
       "      <th>positive_word_proportion</th>\n",
       "      <th>negative_word_proportion</th>\n",
       "      <th>uncertainty_word_proportion</th>\n",
       "      <th>constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>06-03-1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>4093</td>\n",
       "      <td>22464</td>\n",
       "      <td>-0.691757</td>\n",
       "      <td>25.796134</td>\n",
       "      <td>...</td>\n",
       "      <td>10.535327</td>\n",
       "      <td>47749</td>\n",
       "      <td>88068</td>\n",
       "      <td>379</td>\n",
       "      <td>535</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.255076</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>164.613084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>15-05-1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>40</td>\n",
       "      <td>136</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.013184</td>\n",
       "      <td>163</td>\n",
       "      <td>445</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.305618</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>17.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>13-08-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>50</td>\n",
       "      <td>162</td>\n",
       "      <td>-0.528302</td>\n",
       "      <td>32.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>13.055971</td>\n",
       "      <td>233</td>\n",
       "      <td>515</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.314563</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>25.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>12-11-1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>2044</td>\n",
       "      <td>11233</td>\n",
       "      <td>-0.692099</td>\n",
       "      <td>22.145282</td>\n",
       "      <td>...</td>\n",
       "      <td>9.081807</td>\n",
       "      <td>24806</td>\n",
       "      <td>44357</td>\n",
       "      <td>297</td>\n",
       "      <td>363</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.253241</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>122.195592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>16-11-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>60</td>\n",
       "      <td>180</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>28.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>11.518531</td>\n",
       "      <td>270</td>\n",
       "      <td>624</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.030449</td>\n",
       "      <td>0.030449</td>\n",
       "      <td>28.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>12239</td>\n",
       "      <td>SPHERIX INC</td>\n",
       "      <td>200704</td>\n",
       "      <td>02-04-2007</td>\n",
       "      <td>10-K</td>\n",
       "      <td>edgar/data/12239/0001104659-07-024804.txt</td>\n",
       "      <td>54416</td>\n",
       "      <td>107502</td>\n",
       "      <td>-0.327857</td>\n",
       "      <td>292.908828</td>\n",
       "      <td>...</td>\n",
       "      <td>117.188446</td>\n",
       "      <td>12607</td>\n",
       "      <td>202400</td>\n",
       "      <td>1449</td>\n",
       "      <td>2652</td>\n",
       "      <td>0.268854</td>\n",
       "      <td>0.531136</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>76.319759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>12239</td>\n",
       "      <td>SPHERIX INC</td>\n",
       "      <td>200705</td>\n",
       "      <td>16-05-2007</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/12239/0001104659-07-040463.txt</td>\n",
       "      <td>41</td>\n",
       "      <td>137</td>\n",
       "      <td>-0.539326</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.013184</td>\n",
       "      <td>163</td>\n",
       "      <td>445</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>0.092135</td>\n",
       "      <td>0.307865</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>17.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>12239</td>\n",
       "      <td>SPHERIX INC</td>\n",
       "      <td>200705</td>\n",
       "      <td>18-05-2007</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/12239/0001104659-07-041441.txt</td>\n",
       "      <td>11706</td>\n",
       "      <td>23259</td>\n",
       "      <td>-0.330416</td>\n",
       "      <td>439.343434</td>\n",
       "      <td>...</td>\n",
       "      <td>175.762839</td>\n",
       "      <td>2769</td>\n",
       "      <td>43495</td>\n",
       "      <td>342</td>\n",
       "      <td>706</td>\n",
       "      <td>0.269134</td>\n",
       "      <td>0.534751</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>61.607649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>12239</td>\n",
       "      <td>SPHERIX INC</td>\n",
       "      <td>200705</td>\n",
       "      <td>23-05-2007</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/12239/0001104659-07-042333.txt</td>\n",
       "      <td>54637</td>\n",
       "      <td>107859</td>\n",
       "      <td>-0.327528</td>\n",
       "      <td>292.585612</td>\n",
       "      <td>...</td>\n",
       "      <td>117.059051</td>\n",
       "      <td>12611</td>\n",
       "      <td>203347</td>\n",
       "      <td>1457</td>\n",
       "      <td>2648</td>\n",
       "      <td>0.268688</td>\n",
       "      <td>0.530418</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>76.792674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12239</td>\n",
       "      <td>SPHERIX INC</td>\n",
       "      <td>200708</td>\n",
       "      <td>14-08-2007</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/12239/0001104659-07-062470.txt</td>\n",
       "      <td>16341</td>\n",
       "      <td>36203</td>\n",
       "      <td>-0.378007</td>\n",
       "      <td>418.869822</td>\n",
       "      <td>...</td>\n",
       "      <td>167.571515</td>\n",
       "      <td>4174</td>\n",
       "      <td>70789</td>\n",
       "      <td>467</td>\n",
       "      <td>965</td>\n",
       "      <td>0.230841</td>\n",
       "      <td>0.511421</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>73.356477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK            CONAME   FYRMO       FDATE     FORM  \\\n",
       "0     3662  SUNBEAM CORP/FL/  199803  06-03-1998  10-K405   \n",
       "1     3662  SUNBEAM CORP/FL/  199805  15-05-1998     10-Q   \n",
       "2     3662  SUNBEAM CORP/FL/  199808  13-08-1998  NT 10-Q   \n",
       "3     3662  SUNBEAM CORP/FL/  199811  12-11-1998   10-K/A   \n",
       "4     3662  SUNBEAM CORP/FL/  199811  16-11-1998  NT 10-Q   \n",
       "..     ...               ...     ...         ...      ...   \n",
       "147  12239       SPHERIX INC  200704  02-04-2007     10-K   \n",
       "148  12239       SPHERIX INC  200705  16-05-2007  NT 10-Q   \n",
       "149  12239       SPHERIX INC  200705  18-05-2007     10-Q   \n",
       "150  12239       SPHERIX INC  200705  23-05-2007   10-K/A   \n",
       "151  12239       SPHERIX INC  200708  14-08-2007     10-Q   \n",
       "\n",
       "                                      SECFNAME  positive_score  \\\n",
       "0     edgar/data/3662/0000950170-98-000413.txt            4093   \n",
       "1     edgar/data/3662/0000950170-98-001001.txt              40   \n",
       "2     edgar/data/3662/0000950172-98-000783.txt              50   \n",
       "3     edgar/data/3662/0000950170-98-002145.txt            2044   \n",
       "4     edgar/data/3662/0000950172-98-001203.txt              60   \n",
       "..                                         ...             ...   \n",
       "147  edgar/data/12239/0001104659-07-024804.txt           54416   \n",
       "148  edgar/data/12239/0001104659-07-040463.txt              41   \n",
       "149  edgar/data/12239/0001104659-07-041441.txt           11706   \n",
       "150  edgar/data/12239/0001104659-07-042333.txt           54637   \n",
       "151  edgar/data/12239/0001104659-07-062470.txt           16341   \n",
       "\n",
       "     negative_score  polarity_score  average_sentence_length  ...   fog_index  \\\n",
       "0             22464       -0.691757                25.796134  ...   10.535327   \n",
       "1               136       -0.545455                29.666667  ...   12.013184   \n",
       "2               162       -0.528302                32.187500  ...   13.055971   \n",
       "3             11233       -0.692099                22.145282  ...    9.081807   \n",
       "4               180       -0.500000                28.363636  ...   11.518531   \n",
       "..              ...             ...                      ...  ...         ...   \n",
       "147          107502       -0.327857               292.908828  ...  117.188446   \n",
       "148             137       -0.539326                29.666667  ...   12.013184   \n",
       "149           23259       -0.330416               439.343434  ...  175.762839   \n",
       "150          107859       -0.327528               292.585612  ...  117.059051   \n",
       "151           36203       -0.378007               418.869822  ...  167.571515   \n",
       "\n",
       "     complex_word_count  word_count  uncertainty_score  constraining_score  \\\n",
       "0                 47749       88068                379                 535   \n",
       "1                   163         445                 16                  25   \n",
       "2                   233         515                 18                  20   \n",
       "3                 24806       44357                297                 363   \n",
       "4                   270         624                 19                  22   \n",
       "..                  ...         ...                ...                 ...   \n",
       "147               12607      202400               1449                2652   \n",
       "148                 163         445                 16                  25   \n",
       "149                2769       43495                342                 706   \n",
       "150               12611      203347               1457                2648   \n",
       "151                4174       70789                467                 965   \n",
       "\n",
       "     positive_word_proportion  negative_word_proportion  \\\n",
       "0                    0.046475                  0.255076   \n",
       "1                    0.089888                  0.305618   \n",
       "2                    0.097087                  0.314563   \n",
       "3                    0.046081                  0.253241   \n",
       "4                    0.096154                  0.288462   \n",
       "..                        ...                       ...   \n",
       "147                  0.268854                  0.531136   \n",
       "148                  0.092135                  0.307865   \n",
       "149                  0.269134                  0.534751   \n",
       "150                  0.268688                  0.530418   \n",
       "151                  0.230841                  0.511421   \n",
       "\n",
       "     uncertainty_word_proportion  constraining_word_proportion  \\\n",
       "0                       0.004303                      0.004303   \n",
       "1                       0.035955                      0.035955   \n",
       "2                       0.034951                      0.034951   \n",
       "3                       0.006696                      0.006696   \n",
       "4                       0.030449                      0.030449   \n",
       "..                           ...                           ...   \n",
       "147                     0.007159                      0.007159   \n",
       "148                     0.035955                      0.035955   \n",
       "149                     0.007863                      0.007863   \n",
       "150                     0.007165                      0.007165   \n",
       "151                     0.006597                      0.006597   \n",
       "\n",
       "     constraining_words_whole_report  \n",
       "0                         164.613084  \n",
       "1                          17.800000  \n",
       "2                          25.750000  \n",
       "3                         122.195592  \n",
       "4                          28.363636  \n",
       "..                               ...  \n",
       "147                        76.319759  \n",
       "148                        17.800000  \n",
       "149                        61.607649  \n",
       "150                        76.792674  \n",
       "151                        73.356477  \n",
       "\n",
       "[152 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\anoop\\Desktop\\finance_website\\final_output_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
