{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You saw the abs function in the previous tutorial, but what if you've forgotten what it does?\n",
    "\n",
    "The help() function is possibly the most important Python function you can learn. If you can remember how to use help(),\n",
    "you hold the key to understanding most other functions.\n",
    "\n",
    "help(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return is another keyword uniquely associated with functions. When Python encounters a return statement, \n",
    "it exits the function immediately, and passes the value on the right hand side to the calling context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"purple\">Docsstrings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Python isn't smart enough to read my code and turn it into a nice English description(for manual funtions made by me). \n",
    "However, when I write a function,I can provide a description in what's called the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_difference(a, b, c):\n",
    "    \"\"\"Return the smallest difference between any two numbers\n",
    "    among a, b and c.\n",
    "    \n",
    "    >>> least_difference(1, 5, -5)\n",
    "    4\n",
    "    \"\"\"\n",
    "    diff1 = abs(a - b)\n",
    "    diff2 = abs(b - c)\n",
    "    diff3 = abs(a - c)\n",
    "    return min(diff1, diff2, diff3)\n",
    "\n",
    "The docstring is a triple-quoted string (which may span multiple lines) that comes immediately after the header of a \n",
    "function. When we call help() on a function, it shows the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_difference(a, b, c):\n",
    "    \"\"\"Return the smallest difference between any two numbers\n",
    "    among a, b and c.\n",
    "    \n",
    "    >>> least_difference(1, 5, -5)\n",
    "    4\n",
    "    \"\"\"\n",
    "    diff1 = abs(a - b)\n",
    "    diff2 = abs(b - c)\n",
    "    diff3 = abs(a - c)\n",
    "    return min(diff1, diff2, diff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function least_difference in module __main__:\n",
      "\n",
      "least_difference(a, b, c)\n",
      "    Return the smallest difference between any two numbers\n",
      "    among a, b and c.\n",
      "    \n",
      "    >>> least_difference(1, 5, -5)\n",
      "    4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(least_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Green\">Return </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return is another keyword uniquely associated with functions. When Python encounters a return statement, \n",
    "it exits the function immediately, and passes the value on the right hand side to the calling context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What would happen if we didn't include the return keyword in our function?\n",
    "Python allows us to define such functions. The result of calling them is the special value None. \n",
    "(This is similar to the concept of \"null\" in other languages.)\n",
    "\n",
    "Without a return statement, least_difference is completely pointless, but a function with side effects may do something \n",
    "useful without returning anything. We've already seen two examples of this: print() and help() don't return anything.\n",
    "We only call them for their side effects (putting some text on the screen). Other examples of useful side effects \n",
    "include writing to a file, or modifying an input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mystery = print()\n",
    "print(mystery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Funtions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greet Lord Ashish\n",
      "Greet World\n",
      "Greet EveryBody\n"
     ]
    }
   ],
   "source": [
    "def greet(who=\"Lord Ashish\"):\n",
    "    print(\"Greet\",who)\n",
    "greet()\n",
    "greet(\"World\")\n",
    "greet(who=\"EveryBody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions Applied to Functions\n",
    "Here's something that's powerful, though it can feel very abstract at first. You can supply functions as arguments to\n",
    "other functions. Some example may make this clearer:\n",
    "\n",
    "def mult_by_five(x):\n",
    "    return 5 * x\n",
    "\n",
    "def call(fn, arg):\n",
    "    \"\"\"Call fn on arg\"\"\"\n",
    "    return fn(arg)\n",
    "\n",
    "def squared_call(fn, arg):\n",
    "    \"\"\"Call fn on the result of calling fn on arg\"\"\"\n",
    "    return fn(fn(arg))\n",
    "\n",
    "print(\n",
    "    call(mult_by_five, 1),\n",
    "    squared_call(mult_by_five, 1), \n",
    "    sep='\\n', # '\\n' is the newline character - it starts a new line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions that operate on other functions are called \"higher-order functions.\" You probably won't write your own for a\n",
    "little while. But there are higher-order functions built into Python that you might find useful to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As you've seen, ndigits=-1 rounds to the nearest 10, ndigits=-2 rounds to the nearest 100 and so on. Where might this be\n",
    "useful? Suppose we're dealing with large numbers:\n",
    "\n",
    "The area of Finland is 338,424 km²\n",
    "The area of Greenland is 2,166,086 km²\n",
    "\n",
    "We probably don't care whether it's really 338,424, or 338,425, or 338,177. All those digits of accuracy are just \n",
    "distracting. We can chop them off by calling round() with ndigits=-3:\n",
    "\n",
    "The area of Finland is 338,000 km²\n",
    "The area of Greenland is 2,166,000 km²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Python has a type of variable called bool. It has two possible values: True and False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remember to use == instead of = when making comparisons. If you write n == 2 you are asking about the value of n. \n",
    "When you write n = 2 you are changing the value of n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boolean conversion\n",
    "We've seen int(), which turns things into ints, and float(), which turns things into floats, so you might not be surprised\n",
    "to hear that Python has a bool() function which turns things into bools.\n",
    "\n",
    "print(bool(1)) # all numbers are treated as true, except 0\n",
    "print(bool(0))\n",
    "print(bool(\"asf\")) # all strings are treated as true, except the empty string \"\"\n",
    "print(bool(\"\"))\n",
    "# Generally empty sequences (strings, lists, and other types we've yet to see like lists and tuples)\n",
    "# are \"falsey\" and the rest are \"truthy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 1 candy\n"
     ]
    }
   ],
   "source": [
    "total_candies=1\n",
    "print(\"Splitting\", total_candies, \"candy\" if total_candies == 1 else \"candies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wants_plain_hotdog(ketchup, mustard, onion):\n",
    "    \"\"\"Return whether the customer wants a plain hot dog with no toppings.\n",
    "    \"\"\"\n",
    "    return not ketchup and not mustard and not onion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactly_one_sauce(ketchup, mustard, onion):\n",
    "    \"\"\"Return whether the customer wants either ketchup or mustard, but not both.\n",
    "    (You may be familiar with this operation under the name \"exclusive or\")\n",
    "    \"\"\"\n",
    "    return (ketchup and not mustard) or (mustard and not ketchup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepared_for_weather(have_umbrella, rain_level, have_hood, is_workday):\n",
    "    # Don't change this code. Our goal is just to find the bug, not fix it!\n",
    "    return have_umbrella or (rain_level < 5 and have_hood) or not (rain_level > 0 and is_workday)\n",
    "\n",
    "# Change the values of these inputs so they represent a case where prepared_for_weather\n",
    "# returns the wrong answer.\n",
    "have_umbrella = False\n",
    "rain_level = 0.0\n",
    "have_hood = False\n",
    "is_workday = False\n",
    "\n",
    "# Check what the function returns given the current values of the variables above\n",
    "actual = prepared_for_weather(have_umbrella, rain_level, have_hood, is_workday)\n",
    "print(actual)\n",
    "\n",
    "# Check your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactly_one_topping(ketchup, mustard, onion):\n",
    "    \"\"\"Return whether the customer wants exactly one of the three available toppings\n",
    "    on their hot dog.\n",
    "    \"\"\"\n",
    "    return (ketchup + mustard + onion)==1\n",
    "# Check your answer\n",
    "q6.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In object-oriented programming languages like Python, an object is an entity that contains data along with associated\n",
    "metadata and/or functionality. In Python everything is an object, which means every entity has some metadata \n",
    "(called attributes) and associated functionality (called methods). These attributes and methods are accessed via the dot\n",
    "syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The things an object carries around can also include functions. A function attached to an object is called a method.\n",
    "(Non-function things attached to an object, such as imag, are called attributes).\n",
    "\n",
    "For example, numbers have a method called bit_length. Again, we access it using dot syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=18\n",
    "x.bit_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets=['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "planets.index(\"Earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is earth in planets\n",
    "\"Earth\" in planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Pluto\" in planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [1, 2, 3][1:]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercury @Venus @Earth @Mars @Jupiter @Saturn @Uranus @Neptune @"
     ]
    }
   ],
   "source": [
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "for planet in planets:\n",
    "    print(planet, end=' ') # print all on same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In addition to lists, we can iterate over the elements of a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO"
     ]
    }
   ],
   "source": [
    "s = 'steganograpHy is the practicE of conceaLing a file, message, image, or video within another fiLe, message, image, Or video.'\n",
    "msg = ''\n",
    "# print all the uppercase letters in s, one at a time\n",
    "for char in s:\n",
    "    if char.isupper():\n",
    "        print(char, end='')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VENUS!', 'EARTH!', 'MARS!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loud_short_planets = [planet.upper() + '!' for planet in planets if len(planet) < 6]\n",
    "loud_short_planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Continuing the SQL analogy, you could think of these three lines as SELECT, FROM, and WHERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_negatives(nums):\n",
    "    return len([num for num in nums if num < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_negatives(nums):\n",
    "    # Reminder: in the \"booleans and conditionals\" exercises, we learned about a quirk of \n",
    "    # Python where it calculates something like True + True + False + True to be equal to 3.\n",
    "    return sum([num < 0 for num in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_lucky_number(nums):\n",
    "    return any([num % 7 == 0 for num in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " has_lucky_number([10,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2>4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_greater_than(L, thresh):\n",
    "    return [ele > thresh for ele in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-45-b898d8496c47>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-b898d8496c47>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    return True\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "j=1\n",
    "while j<len(meals):\n",
    "    if meals[i]==meals[j]:\n",
    "         return True\n",
    "else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Strings and dictionary</color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Strings are sequences\n",
    "1. Strings can be thought of as sequences of characters. Almost everything we've seen that we can do to a list,\n",
    "we can also do to a string.\n",
    "2. But a major way in which they differ from lists is that they are immutable. We can't modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-a43631749f52>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-47-a43631749f52>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    'Pluto's a planet!'\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'Pluto's a planet!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pluto's  a planet\n"
     ]
    }
   ],
   "source": [
    "print('pluto\\'s  a planet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's up? That's \"cool\" Look, a mountain: /\\\n"
     ]
    }
   ],
   "source": [
    "print('What\\'s up?',\"That's \\\"cool\\\"\",\"Look, a mountain: /\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look, a mountain: /\\ \n",
      "1\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Look, a mountain: /\\\\\",  \"\\n1\\n2 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"1 \\n 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# startswith and endswidth\n",
    "claim=\"Thousand Dollar $\"\n",
    "claim.startswith(\"Th\"),claim.endswith(\"$\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Going between strings and lists: .split() and .join()\n",
    "str.split() turns a string into a list of smaller strings, breaking on whitespace by default. \n",
    "This is super useful for taking you from one big string to a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are', 'You']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"Hello How are You\"\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occasionally you'll want to split on something other than whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1956', '01', '31']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestr = '1956-01-31'\n",
    "datestr.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.join() takes us in the other direction, sewing a list of strings up into one long string,\n",
    "using the string it was called on as a separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLAP 👏 CLAP 👏 CLAP'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' 👏 '.join([word.upper() for word in ['clap','clap','clap']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pluto, you'll always be the 9th planet to me.Happy\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planet=\"Pluto\"\n",
    "position=\"9\"\n",
    "last=\"Happy\"\n",
    "\"{}, you'll always be the {}th planet to me.{}\".format(planet, position,last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "So much cleaner! We call .format() on a \"format string\", where the Python values we want to insert \n",
    "are represented with {} placeholders.\n",
    "\n",
    "Notice how we didn't even have to call str() to convert position from an int. format() takes care of that for us.\n",
    "\n",
    "If that was all that format() did, it would still be incredibly useful. But as it turns out, it can do a lot more.\n",
    "Here's just a taste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pluto weighs about 1.3e+22 kilograms (0.218% of Earth's mass). It is home to 52,910,390 Plutonians.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto_mass = 1.303 * 10**22\n",
    "earth_mass = 5.9722 * 10**24\n",
    "population = 52910390\n",
    "#         2 decimal points   3 decimal points, format as percent     separate with commas\n",
    "\"{} weighs about {:.2} kilograms ({:.3%} of Earth's mass). It is home to {:,} Plutonians.\".format(\n",
    "    planet, pluto_mass, pluto_mass / earth_mass, population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pluto's a planet.\n",
      "No, it's a dwarf planet.\n",
      "planet!\n",
      "dwarf planet!\n"
     ]
    }
   ],
   "source": [
    "# Referring to format() arguments by index, starting from 0\n",
    "s = \"\"\"Pluto's a {0}.\n",
    "No, it's a {1}.\n",
    "{0}!\n",
    "{1}!\"\"\".format('planet', 'dwarf planet')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' sea shells on the sea shore'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" {0} shells on the {0} {1}\".format(\"sea\",\"shore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mercury': 'M',\n",
       " 'Venus': 'V',\n",
       " 'Earth': 'E',\n",
       " 'Mars': 'M',\n",
       " 'Jupiter': 'J',\n",
       " 'Saturn': 'S',\n",
       " 'Uranus': 'U',\n",
       " 'Neptune': 'N'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python has dictionary comprehensions with a syntax similar to the list comprehensions we saw in the previous tutorial.\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "planet_to_initial = {planet: planet[0] for planet in planets}\n",
    "planet_to_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The in operator tells us whether something is a key in the dictionary\n",
    "\"Venus\" in planets,\"Hello\" in planets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# A for loop over a dictionary will loop over its keys\n",
    "for k in planets:\n",
    "    print(\"{} = {}\".format(k, numbers[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercury M\n",
      "Venus V\n",
      "Earth E\n",
      "Mars M\n",
      "Jupiter J\n",
      "Saturn S\n",
      "Uranus U\n",
      "Neptune N\n"
     ]
    }
   ],
   "source": [
    "for i,j in planet_to_initial.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = '\\n'\n",
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'it\\'s ok'\n",
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module builtins:\n",
      "\n",
      "class str(object)\n",
      " |  str(object='') -> str\n",
      " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
      " |  \n",
      " |  Create a new string object from the given object. If encoding or\n",
      " |  errors is specified, then the object must expose a data buffer\n",
      " |  that will be decoded using the given encoding and error handler.\n",
      " |  Otherwise, returns the result of object.__str__() (if defined)\n",
      " |  or repr(object).\n",
      " |  encoding defaults to sys.getdefaultencoding().\n",
      " |  errors defaults to 'strict'.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(self, format_spec, /)\n",
      " |      Return a formatted version of the string as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(self, /)\n",
      " |      Return the size of the string in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(self, /)\n",
      " |      Return a capitalized version of the string.\n",
      " |      \n",
      " |      More specifically, make the first character have upper case and the rest lower\n",
      " |      case.\n",
      " |  \n",
      " |  casefold(self, /)\n",
      " |      Return a version of the string suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(self, width, fillchar=' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Encode the string using the codec registered for encoding.\n",
      " |      \n",
      " |      encoding\n",
      " |        The encoding in which to encode the string.\n",
      " |      errors\n",
      " |        The error handling scheme to use for encoding errors.\n",
      " |        The default is 'strict' meaning that encoding errors raise a\n",
      " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      " |        'xmlcharrefreplace' as well as any other name registered with\n",
      " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |      \n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(self, /)\n",
      " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isalpha(self, /)\n",
      " |      Return True if the string is an alphabetic string, False otherwise.\n",
      " |      \n",
      " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isascii(self, /)\n",
      " |      Return True if all characters in the string are ASCII, False otherwise.\n",
      " |      \n",
      " |      ASCII characters have code points in the range U+0000-U+007F.\n",
      " |      Empty string is ASCII too.\n",
      " |  \n",
      " |  isdecimal(self, /)\n",
      " |      Return True if the string is a decimal string, False otherwise.\n",
      " |      \n",
      " |      A string is a decimal string if all characters in the string are decimal and\n",
      " |      there is at least one character in the string.\n",
      " |  \n",
      " |  isdigit(self, /)\n",
      " |      Return True if the string is a digit string, False otherwise.\n",
      " |      \n",
      " |      A string is a digit string if all characters in the string are digits and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  isidentifier(self, /)\n",
      " |      Return True if the string is a valid Python identifier, False otherwise.\n",
      " |      \n",
      " |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
      " |      such as \"def\" or \"class\".\n",
      " |  \n",
      " |  islower(self, /)\n",
      " |      Return True if the string is a lowercase string, False otherwise.\n",
      " |      \n",
      " |      A string is lowercase if all cased characters in the string are lowercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  isnumeric(self, /)\n",
      " |      Return True if the string is a numeric string, False otherwise.\n",
      " |      \n",
      " |      A string is numeric if all characters in the string are numeric and there is at\n",
      " |      least one character in the string.\n",
      " |  \n",
      " |  isprintable(self, /)\n",
      " |      Return True if the string is printable, False otherwise.\n",
      " |      \n",
      " |      A string is printable if all of its characters are considered printable in\n",
      " |      repr() or if it is empty.\n",
      " |  \n",
      " |  isspace(self, /)\n",
      " |      Return True if the string is a whitespace string, False otherwise.\n",
      " |      \n",
      " |      A string is whitespace if all characters in the string are whitespace and there\n",
      " |      is at least one character in the string.\n",
      " |  \n",
      " |  istitle(self, /)\n",
      " |      Return True if the string is a title-cased string, False otherwise.\n",
      " |      \n",
      " |      In a title-cased string, upper- and title-case characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |  \n",
      " |  isupper(self, /)\n",
      " |      Return True if the string is an uppercase string, False otherwise.\n",
      " |      \n",
      " |      A string is uppercase if all cased characters in the string are uppercase and\n",
      " |      there is at least one cased character in the string.\n",
      " |  \n",
      " |  join(self, iterable, /)\n",
      " |      Concatenate any number of strings.\n",
      " |      \n",
      " |      The string whose method is called is inserted in between each given string.\n",
      " |      The result is returned as a new string.\n",
      " |      \n",
      " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      " |  \n",
      " |  ljust(self, width, fillchar=' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(self, /)\n",
      " |      Return a copy of the string converted to lowercase.\n",
      " |  \n",
      " |  lstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string.  If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing the original string\n",
      " |      and two empty strings.\n",
      " |  \n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |      \n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |      \n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(self, width, fillchar=' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |      \n",
      " |      Padding is done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the string into three parts using the given separator.\n",
      " |      \n",
      " |      This will search for the separator in the string, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |      \n",
      " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      " |      and the original string.\n",
      " |  \n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |        sep\n",
      " |          The delimiter according which to split the string.\n",
      " |          None (the default value) means split according to any whitespace,\n",
      " |          and discard empty strings from the result.\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |      \n",
      " |      Splits are done starting at the end of the string and working to the front.\n",
      " |  \n",
      " |  rstrip(self, chars=None, /)\n",
      " |      Return a copy of the string with trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the words in the string, using sep as the delimiter string.\n",
      " |      \n",
      " |      sep\n",
      " |        The delimiter according which to split the string.\n",
      " |        None (the default value) means split according to any whitespace,\n",
      " |        and discard empty strings from the result.\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |  \n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the string, breaking at line boundaries.\n",
      " |      \n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(self, chars=None, /)\n",
      " |      Return a copy of the string with leading and trailing whitespace removed.\n",
      " |      \n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(self, /)\n",
      " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      " |  \n",
      " |  title(self, /)\n",
      " |      Return a version of the string where each word is titlecased.\n",
      " |      \n",
      " |      More specifically, words start with uppercased characters and all remaining\n",
      " |      cased characters have lower case.\n",
      " |  \n",
      " |  translate(self, table, /)\n",
      " |      Replace each character in the string using the given translation table.\n",
      " |      \n",
      " |        table\n",
      " |          Translation table, which must be a mapping of Unicode ordinals to\n",
      " |          Unicode ordinals, strings, or None.\n",
      " |      \n",
      " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      " |      dictionary or list.  If this operation raises LookupError, the character is\n",
      " |      left untouched.  Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(self, /)\n",
      " |      Return a copy of the string converted to uppercase.\n",
      " |  \n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |      \n",
      " |      The string is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  maketrans(...)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=\"10000e\"\n",
    "ex.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_zip(zip_str):\n",
    "    return len(zip_str) == 5 and zip_str.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = [\"The Learn Python Challenge Casino.\", \"They bought a car\", \"Casinoville\"]\n",
    "arr=[]\n",
    "keyword=\"car\"\n",
    "def find(doc_list,keyword):\n",
    "    arr=[]\n",
    "    for i in range(len(doc_list)):\n",
    "        l=doc_list[i].lower()\n",
    "        l=l.split()\n",
    "        if keyword.lower() in l:\n",
    "            arr.append(i)\n",
    "    return arr\n",
    "find(doc_list,\"Car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'learn', 'python', 'challenge', 'casino.'] ['the', 'learn', 'python', 'challenge', 'casino']\n",
      "['they', 'bought', 'a', 'car'] ['they', 'bought', 'a', 'car']\n",
      "['casinoville'] ['casinoville']\n"
     ]
    }
   ],
   "source": [
    "arr=[]\n",
    "for i in range(len(doc_list)):\n",
    "    l=doc_list[i].lower()\n",
    "    l=l.split()\n",
    "    r=[token.strip('.,').lower() for token in l]\n",
    "    print(l,r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(doc_list, keyword):\n",
    "    \"\"\"\n",
    "    Takes a list of documents (each document is a string) and a keyword. \n",
    "    Returns list of the index values into the original list for all documents \n",
    "    containing the keyword.\n",
    "​\n",
    "    Example:\n",
    "    doc_list = [\"The Learn Python Challenge Casino.\", \"They bought a car\", \"Casinoville\"]\n",
    "    >>> word_search(doc_list, 'casino')\n",
    "    >>> [0]\n",
    "    \"\"\"\n",
    "    indices = [] \n",
    "    # Iterate through the indices (i) and elements (doc) of documents\n",
    "    for i, doc in enumerate(doc_list):\n",
    "        # Split the string doc into a list of words (according to whitespace)\n",
    "        tokens = doc.split()\n",
    "        # Make a transformed list where we 'normalize' each word to facilitate matching.\n",
    "        # Periods and commas are removed from the end of each word, and it's set to all lowercase.\n",
    "        normalized = [token.rstrip('.,').lower() for token in tokens]\n",
    "        # Is there a match? If so, update the list of matching indices.\n",
    "        if keyword.lower() in normalized:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 2: 3, 3: 4}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[2,3,4]\n",
    "dict(zip(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_word_search(documents, keywords):\n",
    "    keyword_to_indices = {}\n",
    "    for keyword in keywords:\n",
    "        keyword_to_indices[keyword] = word_search(documents, keyword)\n",
    "    return keyword_to_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math is a module. A module is just a collection of variables (a namespace, if you like) defined by someone else.\n",
    "We can see all the names in math using the built-in function dir()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 3.141592653589793)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import *\n",
    "log(16,2),pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Three tools for understanding strange objects\n",
    "In the cell above, we saw that calling a numpy function gave us an \"array\".\n",
    "We've never seen anything like this before (not in this course anyways). But don't panic: we have three familiar builtin functions to help us here.\n",
    "\n",
    "1: type() (what is this thing?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 5, 2, 1, 1, 4, 2, 5, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "rolls = numpy.random.randint(low=1, high=6, size=10)\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2: dir() (what can I do with it?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, [4, 4, 5, 2, 1, 1, 4, 2, 5, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls.mean(),rolls.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 :help() (tell me more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ravel:\n",
      "\n",
      "ravel(...) method of numpy.ndarray instance\n",
      "    a.ravel([order])\n",
      "    \n",
      "    Return a flattened array.\n",
      "    \n",
      "    Refer to `numpy.ravel` for full documentation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.ravel : equivalent function\n",
      "    \n",
      "    ndarray.flat : a flat iterator on the array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rolls.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 3, 4, 6, 7, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=numpy.array([[1,2,3],[4,3,4],[6,7,6]])\n",
    "a.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True,  True, False,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls<=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlist = [[1, 2, 3], [2, 4, 6]]\n",
      "x =\n",
      "[[1 2 3]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "xlist = [[1,2,3],[2,4,6],]\n",
    "# Create a 2-dimensional array\n",
    "x = numpy.asarray(xlist)\n",
    "print(\"xlist = {}\\nx =\\n{}\".format(xlist, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Oveloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his turns out to be directly related to operator overloading.\n",
    "\n",
    "When Python programmers want to define how operators behave on their types, they do so by implementing methods \n",
    "with special names beginning and ending with 2 underscores such as __lt__, __setattr__, or __contains__. Generally, names that follow this double-underscore format have a special meaning to Python.\n",
    "\n",
    "So, for example, the expression x in [1, 2, 3] is actually calling the list method __contains__ behind-the-scenes. \n",
    "It's equivalent to (the much uglier) [1, 2, 3].__contains__(x).\n",
    "\n",
    "If you're curious to learn more, you can check out Python's official documentation, which describes many,\n",
    "many more of these special \"underscores\" methods.\n",
    "\n",
    "We won't be defining our own types in these lessons (if only there was time!), but I hope you'll get to experience\n",
    "the joys of defining your own wonderful, weird types later down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackjack_hand_greater_than(hand_1, hand_2):\n",
    "    \"\"\"\n",
    "    Return True if hand_1 beats hand_2, and False otherwise.\n",
    "    \n",
    "    In order for hand_1 to beat hand_2 the following must be true:\n",
    "    - The total of hand_1 must not exceed 21\n",
    "    - The total of hand_1 must exceed the total of hand_2 OR hand_2's total must exceed 21\n",
    "    \n",
    "    Hands are represented as a list of cards. Each card is represented by a string.\n",
    "    \n",
    "    When adding up a hand's total, cards with numbers count for that many points. Face\n",
    "    cards ('J', 'Q', and 'K') are worth 10 points. 'A' can count for 1 or 11.\n",
    "    \n",
    "    When determining a hand's total, you should try to count aces in the way that \n",
    "    maximizes the hand's total without going over 21. e.g. the total of ['A', 'A', '9'] is 21,\n",
    "    the total of ['A', 'A', '9', '3'] is 14.\n",
    "    \n",
    "    Examples:\n",
    "    >>> blackjack_hand_greater_than(['K'], ['3', '4'])\n",
    "    True\n",
    "    >>> blackjack_hand_greater_than(['K'], ['10'])\n",
    "    False\n",
    "    >>> blackjack_hand_greater_than(['K', 'K', '2'], ['3'])\n",
    "    False\n",
    "    \"\"\"\n",
    "    \"J\"=\"K\"=\"Q\"=10\n",
    "    if \n",
    "    \n",
    "# Check your answer\n",
    "q3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_total(hand):\n",
    "    \"\"\"Helper function to calculate the total points of a blackjack hand.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    # Count the number of aces and deal with how to apply them at the end.\n",
    "    aces = 0\n",
    "    for card in hand:\n",
    "        if card in ['J', 'Q', 'K']:\n",
    "            total += 10\n",
    "        elif card == 'A':\n",
    "            aces += 1\n",
    "        else:\n",
    "            # Convert number cards (e.g. '7') to ints\n",
    "            total += int(card)\n",
    "    # At this point, total is the sum of this hand's cards *not counting aces*.\n",
    "\n",
    "    # Add aces, counting them as 1 for now. This is the smallest total we can make from this hand\n",
    "    total += aces\n",
    "    # \"Upgrade\" aces from 1 to 11 as long as it helps us get closer to 21\n",
    "    # without busting\n",
    "    while total + 10 <= 21 and aces > 0:\n",
    "        # Upgrade an ace from 1 to 11\n",
    "        total += 10\n",
    "        aces -= 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We use data to decide how to break the houses into two groups, and then again to determine the predicted price in\n",
    "each group. This step of capturing patterns from data is called fitting or training the model. The data used to fit the \n",
    "model is called the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is Model Validation\n",
    "You'll want to evaluate almost every model you ever build. In most (though not all) applications, the relevant measure\n",
    "of model quality is predictive accuracy. In other words, will the model's predictions be close to what actually happens.\n",
    "\n",
    "Many people make a huge mistake when measuring predictive accuracy. They make predictions with their training data and \n",
    "compare those predictions to the target values in the training data. You'll see the problem with this approach \n",
    "and how to solve it in a moment, but let's think about how we'd do this first.\n",
    "\n",
    "You'd first need to summarize the model quality into an understandable way. If you compare predicted and actual home\n",
    "values for 10,000 houses, you'll likely find mix of good and bad predictions. Looking through a list of 10,000 predicted\n",
    "and actual values would be pointless. We need to summarize this into a single metric.\n",
    "\n",
    "There are many metrics for summarizing model quality, but we'll start with one called Mean Absolute Error \n",
    "(also called MAE). Let's break down this metric starting with the last word, error.\n",
    "\n",
    "The prediction error for each house is:\n",
    "\n",
    "error=actual−predicted\n",
    "So, if a house cost $150,000 and you predicted it would cost $100,000 the error is $50,000.\n",
    "\n",
    "With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. \n",
    "We then take the average of those absolute errors. This is our measure of model quality. In plain English,\n",
    "it can be said as\n",
    "\n",
    "On average, our predictions are off by about X.\n",
    "\n",
    "To calculate MAE, we first need a model. That is built in a hidden cell below, which you can review by clicking\n",
    "the code button.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The Problem with \"In-Sample\" Scores\n",
    "The measure we just computed can be called an \"in-sample\" score. We used a single \"sample\" of houses for both building\n",
    "the model and evaluating it. Here's why this is bad.\n",
    "\n",
    "Imagine that, in the large real estate market, door color is unrelated to home price.\n",
    "\n",
    "However, in the sample of data you used to build the model, all homes with green doors were very expensive. \n",
    "The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict\n",
    "high prices for homes with green doors.\n",
    "\n",
    "Since this pattern was derived from the training data, the model will appear accurate in the training data.\n",
    "\n",
    "But if this pattern doesn't hold when the model sees new data, the model would be very inaccurate when used in practice.\n",
    "\n",
    "Since models' practical value come from making predictions on new data, we measure performance on data that wasn't used \n",
    "to build the model. The most straightforward way to do this is to exclude some data from the model-building process,\n",
    "and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score from Approach 1 (Drop Columns with Missing Values)\n",
    "Since we are working with both training and validation sets, we are careful to drop the same columns in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score from Approach 2 (Imputation)\n",
    "Next, we use SimpleImputer to replace missing values with the mean value along each column.\n",
    "\n",
    "Although it's simple, filling in the mean value generally performs quite well (but this varies by dataset). \n",
    "While statisticians have experimented with more complex ways to determine imputed values (such as regression imputation,\n",
    "for instance), the complex strategies typically give no additional benefit once you plug the results into sophisticated\n",
    "machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score from Approach 3 (An Extension to Imputation)\n",
    "Next, we impute the missing values, while also keeping track of which values were imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Given that thre are so few missing values in the dataset, we'd expect imputation to perform better than dropping columns \n",
    "entirely. However, we see that dropping columns performs slightly better! While this can probably partially be attributed\n",
    "to noise in the dataset, another potential explanation is that the imputation method is not a great match to this dataset.\n",
    "That is, maybe instead of filling in the mean value, it makes more sense to set every missing value to a value of 0,\n",
    "to fill in the most frequently encountered value, or to use some other method. For instance, consider the GarageYrBlt \n",
    "column (which indicates the year that the garage was built). It's likely that in some cases, a missing value could \n",
    "indicate a house that does not have a garage. Does it make more sense to fill in the median value along each column in \n",
    "this case? Or could we get better results by filling in the minimum value along each column? It's not quite clear what's\n",
    "best in this case, but perhaps we can rule out some options immediately - for instance, setting missing values in this \n",
    "column to 0 is likely to yield horrible results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Three Approaches\n",
    "1) Drop Categorical Variables\n",
    "\n",
    "2) Ordinal Encoding\n",
    "Ordinal encoding assigns each unique value to a different integer.\n",
    "\n",
    "This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3).\n",
    "\n",
    "This assumption makes sense in this example, because there is an indisputable ranking to the categories. \n",
    "Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. \n",
    "For tree-based models (like decision trees and random forests), you can expect ordinal encoding to work well with ordinal \n",
    "variables.\n",
    "\n",
    "3) One-Hot Encoding\n",
    "One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. \n",
    "To understand this, we'll work through an example.\n",
    "\n",
    "In the original dataset, \"Color\" is a categorical variable with three categories: \"Red\", \"Yellow\", and \"Green\". \n",
    "The corresponding one-hot encoding contains one column for each possible value, and one row for each row in the \n",
    "original dataset. Wherever the original value was \"Red\", we put a 1 in the \"Red\" column; if the original value was\n",
    "\"Yellow\", we put a 1 in the \"Yellow\" column, and so on.\n",
    "\n",
    "In contrast to ordinal encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect\n",
    "this approach to work particularly well if there is no clear ordering in the categorical data\n",
    "(e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as\n",
    "nominal variables.\n",
    "One-hot encoding generally does not perform well if the categorical variable takes on a large number of values\n",
    "(i.e., you generally won't use it for variables taking more than 15 different values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score from Approach 3 (One-Hot Encoding)\n",
    "We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be\n",
    "used to customize its behavior.\n",
    "\n",
    "We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the \n",
    "training data, andsetting sparse=False ensures that the encoded columns are returned as a numpy array\n",
    "(instead of a sparse matrix).\n",
    "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode \n",
    "the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names\n",
    "with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The output above shows, for each column with categorical data, the number of unique values in the column. For instance,\n",
    "the 'Street' column in the training data has two unique values: 'Grvl' and 'Pave', corresponding to a gravel road and a\n",
    "paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the cardinality of that categorical variable.\n",
    "For instance, the 'Street' variable has cardinality 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, you'll experiment with one-hot encoding. But, instead of encoding all of the categorical variables in the dataset,\n",
    "you'll only create a one-hot encoding for columns with cardinality less than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipelines are a simple way to keep your data preprocessing and modeling code organized. Specifically, a pipeline bundles \n",
    "preprocessing and modeling steps so you can use the whole bundle as if it were a single step.\n",
    "\n",
    "Many data scientists hack together models without pipelines, but pipelines have some important benefits. Those include:\n",
    "\n",
    "Cleaner Code: Accounting for data at each step of preprocessing can get messy. With a pipeline, you won't need to manually\n",
    "keep track of your training and validation data at each step.\n",
    "\n",
    "Fewer Bugs: There are fewer opportunities to misapply a step or forget a preprocessing step.\n",
    "Easier to Productionize: It can be surprisingly hard to transition a model from a prototype to something deployable at\n",
    "scale. We won't go into the many related concerns here, but pipelines can help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We construct the full pipeline in three steps.\n",
    "\n",
    "Step 1: Define Preprocessing Steps\n",
    "Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to \n",
    "bundle together different preprocessing steps. The code below:\n",
    "\n",
    "imputes missing values in numerical data, and\n",
    "imputes missing values and applies a one-hot encoding to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "​\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient Boosting\n",
    "Gradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\n",
    "\n",
    "It begins by initializing the ensemble with a single model, whose predictions can be pretty naive. (Even if its predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.)\n",
    "\n",
    "Then, we start the cycle:\n",
    "\n",
    "First, we use the current ensemble to generate predictions for each observation in the dataset. To make a prediction, \n",
    "we add the predictions from all models in the ensemble.\n",
    "These predictions are used to calculate a loss function (like mean squared error, for instance).\n",
    "Then, we use the loss function to fit a new model that will be added to the ensemble. Specifically, we determine model \n",
    "parameters so that adding this new model to the ensemble will reduce the loss. (Side note: The \"gradient\" in \"gradient boosting\" refers to the fact that we'll use gradient descent on the loss function to determine the parameters in this new model.)\n",
    "Finally, we add the new model to ensemble, and ...\n",
    "... repeat!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter Tuning\n",
    "XGBoost has a few parameters that can dramatically affect accuracy and training speed. The first parameters you should\n",
    "understand are:\n",
    "\n",
    "n_estimators\n",
    "n_estimators specifies how many times to go through the modeling cycle described above. It is equal to the number of \n",
    "models that we include in the ensemble.\n",
    "\n",
    "Too low a value causes underfitting, which leads to inaccurate predictions on both training data and test data.\n",
    "Too high a value causes overfitting, which causes accurate predictions on training data, but inaccurate predictions on \n",
    "test data (which is what we care about).\n",
    "Typical values range from 100-1000, though this depends a lot on the learning_rate parameter discussed below.\n",
    "\n",
    "Here is the code to set the number of models in the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds\n",
    "early_stopping_rounds offers a way to automatically find the ideal value for n_estimators. Early stopping causes the model\n",
    "to stop iterating when the validation score stops improving, even if we aren't at the hard stop for n_estimators. It's \n",
    "smart to set a high value for n_estimators and then use early_stopping_rounds to find the optimal time to stop iterating.\n",
    "\n",
    "Since random chance sometimes causes a single round where validation scores don't improve, you need to specify a number \n",
    "for how many rounds of straight deterioration to allow before stopping. Setting early_stopping_rounds=5 is a reasonable\n",
    "choice. In this case, we stop after 5 straight rounds of deteriorating validation scores.\n",
    "\n",
    "When using early_stopping_rounds, you also need to set aside some data for calculating the validation scores -\n",
    "this is done by setting the eval_set parameter.\n",
    "\n",
    "We can modify the example above to include early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(n_estimators=500)\n",
    "my_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_valid, y_valid)],\n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "my_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_valid, y_valid)], \n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If you later want to fit a model with all of your data, set n_estimators to whatever value you found to be optimal when\n",
    "run with early stopping.\n",
    "\n",
    "learning_rate\n",
    "Instead of getting predictions by simply adding up the predictions from each component model, we can multiply the \n",
    "predictions from each model by a small number (known as the learning rate) before adding them in.\n",
    "\n",
    "This means each tree we add to the ensemble helps us less. So, we can set a higher value for n_estimators without \n",
    "overfitting. If we use early stopping, the appropriate number of trees will be determined automatically.\n",
    "\n",
    "In general, a small learning rate and large number of estimators will yield more accurate XGBoost models, though it will \n",
    "also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets \n",
    "learning_rate=0.1.\n",
    "\n",
    "Modifying the example above to change the learning rate yields the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "my_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_valid, y_valid)], \n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs\n",
    "On larger datasets where runtime is a consideration, you can use parallelism to build your models faster.\n",
    "It's common to set the parameter n_jobs equal to the number of cores on your machine. On smaller datasets, this won't help.\n",
    "\n",
    "\n",
    "The resulting model won't be any better, so micro-optimizing for fitting time is typically nothing but a distraction.\n",
    "But, it's useful in large datasets where you would otherwise spend a long time waiting during the fit command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n",
    "my_model.fit(X_train, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_valid, y_valid)], \n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it is indeed confusing and poorly documented. Basically with False (e.g. 0) it does not print anything. With any integer,\n",
    "it will print the evaluation score at that step. So for verbose=100 it will tell you the score every 100 iterations.\n",
    "\n",
    "Setting verbose=True is the same as setting it to 1. Thus it will print a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Since there is no preprocessing, we don't need a pipeline (used anyway as best practice!)\n",
    "my_pipeline = make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "cv_scores = cross_val_score(my_pipeline, X, y, \n",
    "                            cv=5,\n",
    "                            scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation accuracy: %f\" % cv_scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
